[{"path":"https://frankiethull.github.io/kuzco/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 kuzco authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://frankiethull.github.io/kuzco/articles/batch-image-processing.html","id":"workflows-for-many-images","dir":"Articles","previous_headings":"","what":"Workflows for Many Images","title":"batch-image-processing","text":"many situations need analyze multiple images. apply multiple functions image. ’ll use qwen2.5vl handle computer vision. qwen2.5vl local model well vision tasks. Maybe surveying private information, sorting family photos, looping CCTV cameras, trying classify –whatever–, vignette help guide towards standardized computer vision workflows tidyverse packages. ’ll showcase loop images dynamic routine can handle various images leverage kuzco classification tasks. ’m going use purrr apply function image given map() function. ’ll also leverage purrr’s in_parallel mirai setup multiple processes . instances may require run multiple functions exact image. ’ll eventually run situation want classify also understand sentiment image. may also want run multiple models. showcases simple way leverage multiple functions one image. may multiple images need examine class, sentiment, look particular object within image. showcased : Using parallelized processes via mirai & purrr’s new in_parallel function. Lastly, crossing images & functions using mirai may use.","code":"mirai::daemons(20, .compute = \"gpu\") llm_results <- purrr::map(image_files,                            purrr::in_parallel(\\(img) kuzco::llm_image_classification(image = img))) mirai::daemons(0) odin <- system.file(\"img/test_img.jpg\", package = \"kuzco\") kuzco::view_image(odin) vision_workflow <- \\(img){      qwen_classifier <- kuzco::llm_image_classification(     image = img,     llm_model = \"qwen2.5vl\",     backend = 'ellmer'   )      pixtral_classifier <- kuzco::llm_image_classification(     image = img,     llm_model = \"pixtral-12b\",     provider = 'mistral',     backend = 'ellmer'   )      pixtral_sentiment <- kuzco::llm_image_sentiment(     image = img,     llm_model = \"pixtral-12b\",     provider = 'mistral',     backend = \"ellmer\"   ) }  mirai::daemons(20, .compute = \"gpu\") llm_results <- purrr::map(odin,                            purrr::in_parallel(\\(img) vision_workflow(image = img))) mirai::daemons(0) # Written by Mete Akcaoglu, edited by Frank Hull # https://github.com/meteakca # https://github.com/frankiethull/kuzco/issues/22#issuecomment-2957159732  process_image <- function(img_path) {   # Classification   classification <- llm_image_classification(     llm_model = \"qwen2.5vl\",     image = img_path,     backend = 'ellmer'   )      # Object detection (e.g., detecting people)   detection <- llm_image_recognition(     llm_model = \"qwen2.5vl\",     image = img_path,     recognize_object = \"dogs\",     backend = 'ellmer'   )      # Return as tibble   tibble::tibble(     file = img_path,     image_classification = classification$image_classification,     primary_object = classification$primary_object,     secondary_object = classification$secondary_object,     image_description = classification$image_description,     image_colors = classification$image_colors,     image_proba_names = paste(unlist(classification$image_proba_names), collapse = \", \"),     image_proba_values = paste(unlist(classification$image_proba_values), collapse = \", \"),     object_recognized = detection$object_recognized,     object_count = detection$object_count,     object_description = detection$object_description,     object_location = detection$object_location   ) }  tictoc::tic() # Apply to all images and combine into one data frame results_df <- map_dfr(image_files, process_image) tictoc::toc() tictoc::tic() mirai::daemons(20, .compute = \"gpu\") results_df <- map_dfr(image_files,                        purrr::in_parallel(\\(img) process_image(img_path = jmg))) mirai::daemons(0) tictoc::toc() tictoc::tic() image_tasks <- list(classify  = kuzco::llm_image_classification,                     sentiment = kuzco::llm_image_sentiment                     )  grid <- expand.grid(files = image_files, tasks = image_tasks)  mirai::daemons(20, .compute = \"gpu\") llm_results <- purrr::map2(as.character(grid$files),                             grid$tasks,                            purrr::in_parallel(\\(img, task) (task(image = img)))) mirai::daemons(0) tictoc::toc()"},{"path":"https://frankiethull.github.io/kuzco/articles/batch-image-processing.html","id":"applying-a-llm-vision-instruct-to-many-images","dir":"Articles","previous_headings":"","what":"applying a llm vision instruct to many images","title":"batch-image-processing","text":"’ll showcase loop images dynamic routine can handle various images leverage kuzco classification tasks. ’m going use purrr apply function image given map() function. ’ll also leverage purrr’s in_parallel mirai setup multiple processes .","code":"mirai::daemons(20, .compute = \"gpu\") llm_results <- purrr::map(image_files,                            purrr::in_parallel(\\(img) kuzco::llm_image_classification(image = img))) mirai::daemons(0)"},{"path":"https://frankiethull.github.io/kuzco/articles/batch-image-processing.html","id":"applying-many-llm-vision-instructs-to-an-image","dir":"Articles","previous_headings":"","what":"applying many llm vision instructs to an image","title":"batch-image-processing","text":"instances may require run multiple functions exact image. ’ll eventually run situation want classify also understand sentiment image. may also want run multiple models. showcases simple way leverage multiple functions one image.","code":"odin <- system.file(\"img/test_img.jpg\", package = \"kuzco\") kuzco::view_image(odin) vision_workflow <- \\(img){      qwen_classifier <- kuzco::llm_image_classification(     image = img,     llm_model = \"qwen2.5vl\",     backend = 'ellmer'   )      pixtral_classifier <- kuzco::llm_image_classification(     image = img,     llm_model = \"pixtral-12b\",     provider = 'mistral',     backend = 'ellmer'   )      pixtral_sentiment <- kuzco::llm_image_sentiment(     image = img,     llm_model = \"pixtral-12b\",     provider = 'mistral',     backend = \"ellmer\"   ) }  mirai::daemons(20, .compute = \"gpu\") llm_results <- purrr::map(odin,                            purrr::in_parallel(\\(img) vision_workflow(image = img))) mirai::daemons(0)"},{"path":"https://frankiethull.github.io/kuzco/articles/batch-image-processing.html","id":"applying-many-instructs-to-many-images","dir":"Articles","previous_headings":"","what":"applying many instructs to many images","title":"batch-image-processing","text":"may multiple images need examine class, sentiment, look particular object within image. showcased : Using parallelized processes via mirai & purrr’s new in_parallel function. Lastly, crossing images & functions using mirai may use.","code":"# Written by Mete Akcaoglu, edited by Frank Hull # https://github.com/meteakca # https://github.com/frankiethull/kuzco/issues/22#issuecomment-2957159732  process_image <- function(img_path) {   # Classification   classification <- llm_image_classification(     llm_model = \"qwen2.5vl\",     image = img_path,     backend = 'ellmer'   )      # Object detection (e.g., detecting people)   detection <- llm_image_recognition(     llm_model = \"qwen2.5vl\",     image = img_path,     recognize_object = \"dogs\",     backend = 'ellmer'   )      # Return as tibble   tibble::tibble(     file = img_path,     image_classification = classification$image_classification,     primary_object = classification$primary_object,     secondary_object = classification$secondary_object,     image_description = classification$image_description,     image_colors = classification$image_colors,     image_proba_names = paste(unlist(classification$image_proba_names), collapse = \", \"),     image_proba_values = paste(unlist(classification$image_proba_values), collapse = \", \"),     object_recognized = detection$object_recognized,     object_count = detection$object_count,     object_description = detection$object_description,     object_location = detection$object_location   ) }  tictoc::tic() # Apply to all images and combine into one data frame results_df <- map_dfr(image_files, process_image) tictoc::toc() tictoc::tic() mirai::daemons(20, .compute = \"gpu\") results_df <- map_dfr(image_files,                        purrr::in_parallel(\\(img) process_image(img_path = jmg))) mirai::daemons(0) tictoc::toc() tictoc::tic() image_tasks <- list(classify  = kuzco::llm_image_classification,                     sentiment = kuzco::llm_image_sentiment                     )  grid <- expand.grid(files = image_files, tasks = image_tasks)  mirai::daemons(20, .compute = \"gpu\") llm_results <- purrr::map2(as.character(grid$files),                             grid$tasks,                            purrr::in_parallel(\\(img, task) (task(image = img)))) mirai::daemons(0) tictoc::toc()"},{"path":"https://frankiethull.github.io/kuzco/articles/cloud-providers.html","id":"local-llms","dir":"Articles","previous_headings":"","what":"local LLMs","title":"cloud-providers","text":"kuzco originally designed work local LLMs “ollamar.” models run using Ollama, supports “ollamar” “ellmer” backends. installing Ollama system, need pull model use locally. install Ollama pull model (preferably vision model) qwen2.5vl install kuzco run AI enabled computer vision tasks Ollama served default provider time, check getting-started README local examples. kuzco can now also utilize cloud-based providers.","code":""},{"path":"https://frankiethull.github.io/kuzco/articles/cloud-providers.html","id":"cloud-llms","dir":"Articles","previous_headings":"","what":"cloud LLMs","title":"cloud-providers","text":"recent months, kuzco attracted significant interest organizations like R-Consortium Posit, well individuals curating lists LLM AI projects R open-source communities. Many users highlighted need supporting non-local LLMs, whether due hardware limitations desire leverage API account Mistral, Google, OpenAI, etc. Given feedback, adding non-local LLM functionality kuzco logical next step. Note provider = \"ollama\" default, change interfere legacy processes. However, “ellmer” backend selected (also default), option change provider needed. Note showcases use Mistral provider. Since cloud providers require API key, API key can set like : exact environment variable use via ellmer. ’re unsure name API key, refer documentation provider ellmer documentation chat provider. ’ve set environment variable, running computer vision tasks becomes straightforward: reference, complete list “providers” available kuzco, along corresponding ellmer “chat” functions:","code":"# via base R: Sys.setenv(MISTRAL_API_KEY = \"the_api_key_via_the_provider\") # or usethis: usethis::edit_r_environ() kuzco::llm_image_classification(provider = \"mistral\", llm_model = \"pixtral-12b\", image = test_img)"},{"path":"https://frankiethull.github.io/kuzco/articles/cloud-providers.html","id":"cloud-example","dir":"Articles","previous_headings":"","what":"cloud example","title":"cloud-providers","text":"Note provider = \"ollama\" default, change interfere legacy processes. However, “ellmer” backend selected (also default), option change provider needed. Note showcases use Mistral provider. Since cloud providers require API key, API key can set like : exact environment variable use via ellmer. ’re unsure name API key, refer documentation provider ellmer documentation chat provider. ’ve set environment variable, running computer vision tasks becomes straightforward:","code":"# via base R: Sys.setenv(MISTRAL_API_KEY = \"the_api_key_via_the_provider\") # or usethis: usethis::edit_r_environ() kuzco::llm_image_classification(provider = \"mistral\", llm_model = \"pixtral-12b\", image = test_img)"},{"path":"https://frankiethull.github.io/kuzco/articles/cloud-providers.html","id":"cloud-provider-dictionary","dir":"Articles","previous_headings":"","what":"cloud provider dictionary","title":"cloud-providers","text":"reference, complete list “providers” available kuzco, along corresponding ellmer “chat” functions:","code":""},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"a-typical-workflow-for-a-single-image","dir":"Articles","previous_headings":"","what":"a typical workflow for a single image","title":"getting-started","text":"image within kuzco get started. feel free substitute image image choice. make things easy, new function kuzco see image, view_image.  decide llm_image_* function call: - llm_image_alt_text - llm_image_classification - llm_image_extract_text - llm_image_recognition - llm_image_sentiment - llm_image_custom easily view results kuzco:","code":"my_image <- file.path(system.file(package = \"kuzco\", \"img/test_img.jpg\")) my_image |>   view_image() llm_results <-     my_image |>     llm_image_classification(llm_model = \"qwen2.5vl\") llm_results |>   view_llm_results()"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"define-a-path-to-an-image","dir":"Articles","previous_headings":"","what":"define a path to an image","title":"getting-started","text":"image within kuzco get started. feel free substitute image image choice.","code":"my_image <- file.path(system.file(package = \"kuzco\", \"img/test_img.jpg\"))"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"view-the-input-image","dir":"Articles","previous_headings":"","what":"view the input image","title":"getting-started","text":"make things easy, new function kuzco see image, view_image.","code":"my_image |>   view_image()"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"apply-computer-vision","dir":"Articles","previous_headings":"","what":"apply computer vision","title":"getting-started","text":"decide llm_image_* function call: - llm_image_alt_text - llm_image_classification - llm_image_extract_text - llm_image_recognition - llm_image_sentiment - llm_image_custom","code":"llm_results <-     my_image |>     llm_image_classification(llm_model = \"qwen2.5vl\")"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"view-the-output-results","dir":"Articles","previous_headings":"","what":"view the output results","title":"getting-started","text":"easily view results kuzco:","code":"llm_results |>   view_llm_results()"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"computer-vision-app","dir":"Articles","previous_headings":"","what":"computer vision app","title":"getting-started","text":"addtion, kuzco shiny app implementation within package. entire workflow can ran within GUI like :","code":"kuzco_app()"},{"path":"https://frankiethull.github.io/kuzco/articles/multilingual-support.html","id":"multilingual-support","dir":"Articles","previous_headings":"","what":"multilingual support","title":"multilingual-support","text":"models capable returning outputs multiple languages. result, became necessary include language specification ensure certain models responded English. step place, switching output language specific computer vision tasks became straightforward & easy implement.","code":"llm_image_classification(   llm_model = \"qwen2.5vl\",    image = test_img,    backend = 'ellmer',   provider = 'ollama',   language = 'English'   ) #>   image_classification primary_object secondary_object #> 1  Portrait of a puppy          puppy                  #>                                                                                                          image_description #> 1 A close-up portrait of a puppy with black and white fur is the main subject, with a red plaid blanket in the background. #>                                              image_colors image_proba_names #> 1 [\"#000000\", \"#FFFFFF\", \"#FF0000\", \"#0000FF\", \"#A52A2A\"]                   #>              image_proba_values #> 1 [0.6, 0.15, 0.08, 0.07, 0.02] llm_image_classification(   llm_model = \"qwen2.5vl\",    image = test_img,    backend = 'ellmer',   provider = 'ollama',   language = 'Spanish'   ) #>   image_classification primary_object secondary_object #> 1              perrito        perrito            pañal #>                                                                                                                                                                                   image_description #> 1 Un adorable perrito de color negro y blanco está echado en la cama. El perrito está mirando directamente a la cámara. Se ven texturas sutiles en el pelaje y un fondo de colcha de cuadros rojos. #>                                    image_colors image_proba_names #> 1 [#000000, #FFFFFF, #D60000, #FF0000, #0000FF]           perrito #>       image_proba_values #> 1 :[0.8,0.0,0.0,0.0,0.0] llm_image_classification(   llm_model = \"qwen2.5vl\",    image = test_img,    backend = 'ellmer',   provider = 'ollama',   language = 'German'   ) #>   image_classification primary_object secondary_object #> 1         Kinderbetten           Hund                  #>                                                           image_description #> 1 Der Bildinhalt zeigt einen Hund, der in der Nähe eines Kinderbetts liegt. #>                                                  image_colors #> 1 [⌘A87, ⌘AADE, ⌘545417, ⌘545417, ⌘AADE, ⌘A87, ⌘38182A, ⌘A87] #>                                                       image_proba_names #> 1 Hund, Bett, Tier, Kind, Hundebett, Tiergesicht, Fell, Haar, Tieraugen #>                                            image_proba_values #> 1 [0.42, 0.106, 0.08, 0.075, 0.045, 0.035, 0.034, 0.09, 0.07] llm_image_classification(   llm_model = \"qwen2.5vl\",    image = test_img,    backend = 'ellmer',   provider = 'ollama',   language = 'Mandarin Chinese'   ) #>   image_classification primary_object secondary_object #> 1         pet portrait          puppy                  #>                                                  image_description #> 1 这是一张黑白相间的小狗的特写照片，它有着独特的眼睛和湿润的鼻子。 #>                                              image_colors image_proba_names #> 1 [\"#990000\", \"#0000FF\", \"#FFC0CB\", \"#000000\", \"#FFFFFF\"]                 [ #>   image_proba_values #> 1                  ["},{"path":"https://frankiethull.github.io/kuzco/articles/multilingual-support.html","id":"english-results","dir":"Articles","previous_headings":"","what":"English Results","title":"multilingual-support","text":"","code":"llm_image_classification(   llm_model = \"qwen2.5vl\",    image = test_img,    backend = 'ellmer',   provider = 'ollama',   language = 'English'   ) #>   image_classification primary_object secondary_object #> 1  Portrait of a puppy          puppy                  #>                                                                                                          image_description #> 1 A close-up portrait of a puppy with black and white fur is the main subject, with a red plaid blanket in the background. #>                                              image_colors image_proba_names #> 1 [\"#000000\", \"#FFFFFF\", \"#FF0000\", \"#0000FF\", \"#A52A2A\"]                   #>              image_proba_values #> 1 [0.6, 0.15, 0.08, 0.07, 0.02]"},{"path":"https://frankiethull.github.io/kuzco/articles/multilingual-support.html","id":"spanish-results","dir":"Articles","previous_headings":"","what":"Spanish Results","title":"multilingual-support","text":"","code":"llm_image_classification(   llm_model = \"qwen2.5vl\",    image = test_img,    backend = 'ellmer',   provider = 'ollama',   language = 'Spanish'   ) #>   image_classification primary_object secondary_object #> 1              perrito        perrito            pañal #>                                                                                                                                                                                   image_description #> 1 Un adorable perrito de color negro y blanco está echado en la cama. El perrito está mirando directamente a la cámara. Se ven texturas sutiles en el pelaje y un fondo de colcha de cuadros rojos. #>                                    image_colors image_proba_names #> 1 [#000000, #FFFFFF, #D60000, #FF0000, #0000FF]           perrito #>       image_proba_values #> 1 :[0.8,0.0,0.0,0.0,0.0]"},{"path":"https://frankiethull.github.io/kuzco/articles/multilingual-support.html","id":"german-results","dir":"Articles","previous_headings":"","what":"German Results","title":"multilingual-support","text":"","code":"llm_image_classification(   llm_model = \"qwen2.5vl\",    image = test_img,    backend = 'ellmer',   provider = 'ollama',   language = 'German'   ) #>   image_classification primary_object secondary_object #> 1         Kinderbetten           Hund                  #>                                                           image_description #> 1 Der Bildinhalt zeigt einen Hund, der in der Nähe eines Kinderbetts liegt. #>                                                  image_colors #> 1 [⌘A87, ⌘AADE, ⌘545417, ⌘545417, ⌘AADE, ⌘A87, ⌘38182A, ⌘A87] #>                                                       image_proba_names #> 1 Hund, Bett, Tier, Kind, Hundebett, Tiergesicht, Fell, Haar, Tieraugen #>                                            image_proba_values #> 1 [0.42, 0.106, 0.08, 0.075, 0.045, 0.035, 0.034, 0.09, 0.07]"},{"path":"https://frankiethull.github.io/kuzco/articles/multilingual-support.html","id":"chinese-results","dir":"Articles","previous_headings":"","what":"Chinese Results","title":"multilingual-support","text":"","code":"llm_image_classification(   llm_model = \"qwen2.5vl\",    image = test_img,    backend = 'ellmer',   provider = 'ollama',   language = 'Mandarin Chinese'   ) #>   image_classification primary_object secondary_object #> 1         pet portrait          puppy                  #>                                                  image_description #> 1 这是一张黑白相间的小狗的特写照片，它有着独特的眼睛和湿润的鼻子。 #>                                              image_colors image_proba_names #> 1 [\"#990000\", \"#0000FF\", \"#FFC0CB\", \"#000000\", \"#FFFFFF\"]                 [ #>   image_proba_values #> 1                  ["},{"path":"https://frankiethull.github.io/kuzco/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Frank Hull. Author, maintainer, copyright holder. Johannes Breuer. Contributor. Jordi Rosell. Contributor.","code":""},{"path":"https://frankiethull.github.io/kuzco/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hull F (2026). kuzco: Computer Vision Large Language Models. R package version 0.1.0, https://frankiethull.github.io/kuzco/.","code":"@Manual{,   title = {kuzco: Computer Vision with Large Language Models},   author = {Frank Hull},   year = {2026},   note = {R package version 0.1.0},   url = {https://frankiethull.github.io/kuzco/}, }"},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"kuzco-","dir":"","previous_headings":"","what":"Computer Vision with Large Language Models","title":"Computer Vision with Large Language Models","text":"{kuzco} simple vision boilerplate built ollama R, top {ollamar} & {ellmer}. {kuzco} designed computer vision assistant, giving local models guidance classifying images return structured data. goal standardize outputs image classification use LLMs alternative option keras torch. {kuzco} currently supports: classification, recognition, sentiment, text extraction, alt-text creation, custom computer vision tasks.","code":""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Computer Vision with Large Language Models","text":"can install development version kuzco like : kuzco 0.1.0 can installed CRAN via install.packages(\"kuzco\")!","code":"devtools::install_github(\"frankiethull/kuzco\")"},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Computer Vision with Large Language Models","text":"basic example shows use kuzco. image want learn : picture puppy odin circa 2019.","code":"library(kuzco) library(ollamar) test_img <- file.path(system.file(package = \"kuzco\"), \"img/test_img.jpg\")"},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-for-image-classification","dir":"","previous_headings":"Example","what":"llm for image classification:","title":"Computer Vision with Large Language Models","text":"","code":"llm_results <- llm_image_classification(llm_model = \"qwen2.5vl\", image = test_img) llm_results |> tibble::as_tibble() #> # A tibble: 1 × 7 #>   image_classification primary_object secondary_object image_description         #>   <chr>                <chr>          <chr>            <chr>                     #> 1 animal portrait      puppy          \"\"               A close-up portrait of a… #> # ℹ 3 more variables: image_colors <chr>, image_proba_names <chr>, #> #   image_proba_values <chr> llm_results |> str() #> tibble [1 × 7] (S3: tbl_df/tbl/data.frame) #>  $ image_classification: chr \"animal portrait\" #>  $ primary_object      : chr \"puppy\" #>  $ secondary_object    : chr \"\" #>  $ image_description   : chr \"A close-up portrait of a fluffy, curious-looking puppy with a striking patch on its head. The puppy has a white\"| __truncated__ #>  $ image_colors        : chr \"The image has a palette with shades of white, black, and hints of gray.\" #>  $ image_proba_names   : chr \"puppy, fur texture, eye, coat\" #>  $ image_proba_values  : chr \"[0.85, 0.10, 0.05, 0.05]\""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-for-image-sentiment","dir":"","previous_headings":"Example","what":"llm for image sentiment:","title":"Computer Vision with Large Language Models","text":"","code":"llm_emotion <- llm_image_sentiment(llm_model = \"qwen2.5vl\", image = test_img)  llm_emotion |> str() #> tibble [1 × 4] (S3: tbl_df/tbl/data.frame) #>  $ image_sentiment      : chr \"positive\" #>  $ image_score          : num 0.8 #>  $ sentiment_description: chr \"The soft, warm lighting and the cute features of the puppy create a feeling of happiness and warmth.\" #>  $ image_keywords       : chr \"cute, friendly, playful, adorable, lovable\""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-for-image-recognition","dir":"","previous_headings":"Example","what":"llm for image recognition:","title":"Computer Vision with Large Language Models","text":"note backend kuzco flexible well. allows users specify ‘ollamar’, suggests structured outputs, ‘ellmer’ enforces structured outputs.","code":"llm_detection <- llm_image_recognition(llm_model = \"qwen2.5vl\",                                         image = test_img,                                        recognize_object = \"nose\")  llm_detection |> str() #> tibble [1 × 4] (S3: tbl_df/tbl/data.frame) #>  $ object_recognized : chr \"TRUE\" #>  $ object_count      : int 1 #>  $ object_description: chr \"A black and white puppy nose, slightly pink inside with dark round nostrils.\" #>  $ object_location   : chr \"center\""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-for-image-text-extraction","dir":"","previous_headings":"Example","what":"llm for image text extraction:","title":"Computer Vision with Large Language Models","text":"kuzco also useful OCR tasks, extracting text images showcased :","code":"text_img <- file.path(system.file(package = \"kuzco\"), \"img/text_img.jpg\")   text_img |> view_image() llm_extract_txt <- llm_image_extract_text(llm_model = \"qwen2.5vl\",                                            image = text_img,                                           backend  = \"ellmer\")  llm_extract_txt |> str() #> tibble [1 × 2] (S3: tbl_df/tbl/data.frame) #>  $ text            : chr \"Picture of Odin\\nas a puppy\\ncirca Q4 2019\" #>  $ confidence_score: num 0.99"},{"path":[]},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-image-customization","dir":"","previous_headings":"newer features","what":"llm image customization:","title":"Computer Vision with Large Language Models","text":"new feature kuzco, fully customizable function. allows users test computer vision techniques without leaving kuzco boilerplate.","code":"llm_customized <- llm_image_custom(llm_model = \"qwen2.5vl\",                                     image = test_img,                                    system_prompt = \"you are a dog breed expert, you know all about dogs.                                                      tell me the primary breed, secondary breed, and a brief description about both.\",                                    image_prompt  = \"tell me what kind of dog is in the image?\",                                    example_df = data.frame(                                      dog_breed_primary = \"hound\",                                      dog_breed_secondary = \"corgi\",                                      dog_breed_information = \"information about the primary and secondary breed\"                                    ))  llm_customized |> str() #> 'data.frame':    1 obs. of  3 variables: #>  $ dog_breed_primary    : chr \"terrier\" #>  $ dog_breed_secondary  : chr \"spotted\" #>  $ dog_breed_information: chr \"The primary breed is likely a terrier based on the facial features and compact size. The secondary breed is 'sp\"| __truncated__"},{"path":[]},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"io-helpers","dir":"","previous_headings":"newer features > additional enhancements:","what":"i/o helpers","title":"Computer Vision with Large Language Models","text":"kuzco now view_image & view_llm_results functions within package, making easy view images display llm results. addition , kuzco now features kuzco_app fully functioning shiny application within package. Making even easier computer vision LLMs R.","code":""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"cloud-based-llms","dir":"","previous_headings":"newer features > additional enhancements:","what":"cloud-based LLMs","title":"Computer Vision with Large Language Models","text":"kuzco now supports LLM providers supported ellmer! ’s correct, can now send images Perplexity, Claude, OpenAI, Gemini, list goes . defaults “ollama” maintain original workflows. Cloud-hosted LLMs generally offer greater speed advanced capabilities, require users obtain API key since inference handled remotely. providers offer free tier usage limits, others . Keep mind using cloud-hosted LLM comes less privacy compared running model locally, enables access powerful, cutting-edge models. get started, users set API key environment select provider-hosted model supports image processing. mistral example using pixtral-12b, still pretty small model. leverages mistral’s compute, instead .","code":"# via base R: Sys.setenv(MISTRAL_API_KEY = \"the_api_key_via_the_provider\") # or usethis: usethis::edit_r_environ() kuzco::llm_image_classification(provider = \"mistral\", llm_model = \"pixtral-12b\", image = test_img)"},{"path":"https://frankiethull.github.io/kuzco/reference/chat_ellmer.html","id":null,"dir":"Reference","previous_headings":"","what":"chat ellmer helper (predates ellmer::chat) — chat_ellmer","title":"chat ellmer helper (predates ellmer::chat) — chat_ellmer","text":"minimal wrapper function switch provider used llm_image* function ellmer backend selected, ollamar supports ollama","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/chat_ellmer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"chat ellmer helper (predates ellmer::chat) — chat_ellmer","text":"","code":"chat_ellmer(provider = \"ollama\")"},{"path":"https://frankiethull.github.io/kuzco/reference/chat_ellmer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"chat ellmer helper (predates ellmer::chat) — chat_ellmer","text":"provider provider, \"ollama\", \"claude\", \"github\"","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/chat_ellmer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"chat ellmer helper (predates ellmer::chat) — chat_ellmer","text":"ellmer function (provider) use kuzco llm_image_* backend ellmer","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/edit_prompt.html","id":null,"dir":"Reference","previous_headings":"","what":"edit prompt — edit_prompt","title":"edit prompt — edit_prompt","text":"edit listed prompt installed kuzco","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/edit_prompt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"edit prompt — edit_prompt","text":"","code":"edit_prompt(prompt)"},{"path":"https://frankiethull.github.io/kuzco/reference/edit_prompt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"edit prompt — edit_prompt","text":"prompt prompt list_prompts()","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/edit_prompt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"edit prompt — edit_prompt","text":"prompt markdown file edit","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/edit_prompt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"edit prompt — edit_prompt","text":"","code":"if (FALSE) { # \\dontrun{ edit_prompt(\"system-prompt-alt-text.md\") } # }"},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco-package.html","id":null,"dir":"Reference","previous_headings":"","what":"kuzco: Computer Vision with Large Language Models — kuzco-package","title":"kuzco: Computer Vision with Large Language Models — kuzco-package","text":"Make computer vision tasks approachable R leveraging Large Language Models. Providing fine-tuned prompts, boilerplate functions, input/output helpers common computer vision workflows, classifying describing images. Functions designed take images input return structured data, helping users build practical applications minimal code.","code":""},{"path":[]},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"kuzco: Computer Vision with Large Language Models — kuzco-package","text":"Maintainer: Frank Hull frankiethull@gmail.com [copyright holder] contributors: Johannes Breuer johannes.breuer@gesis.org (ORCID) [contributor] Jordi Rosell jroselln@gmail.com (ORCID) [contributor]","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco_app.html","id":null,"dir":"Reference","previous_headings":"","what":"shiny kuzco app — kuzco_app","title":"shiny kuzco app — kuzco_app","text":"simple wrapper kuzco make computer vision everyone. -shot via frank hull shiny assistant (https://gallery.shinyapps.io/assistant/)","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"shiny kuzco app — kuzco_app","text":"","code":"kuzco_app()"},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco_app.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"shiny kuzco app — kuzco_app","text":"shiny app instance playground local llms","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco_app.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"shiny kuzco app — kuzco_app","text":"","code":"if (FALSE) { # \\dontrun{ kuzco_app() } # }"},{"path":"https://frankiethull.github.io/kuzco/reference/list_prompts.html","id":null,"dir":"Reference","previous_headings":"","what":"list prompts — list_prompts","title":"list prompts — list_prompts","text":"list prompts installed kuzco","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/list_prompts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"list prompts — list_prompts","text":"","code":"list_prompts()"},{"path":"https://frankiethull.github.io/kuzco/reference/list_prompts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"list prompts — list_prompts","text":"list prompts stored within kuzco","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/list_prompts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"list prompts — list_prompts","text":"","code":"list_prompts() #> [1] \"image-prompt.md\"                 \"system-prompt-alt-text.md\"       #> [3] \"system-prompt-classification.md\" \"system-prompt-extraction.md\"     #> [5] \"system-prompt-recognition.md\"    \"system-prompt-sentiment.md\""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_alt_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Image Alt Text using LLMs — llm_image_alt_text","title":"Image Alt Text using LLMs — llm_image_alt_text","text":"Image Alt Text using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_alt_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image Alt Text using LLMs — llm_image_alt_text","text":"","code":"llm_image_alt_text(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   language = \"English\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_alt_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image Alt Text using LLMs — llm_image_alt_text","text":"llm_model local LLM model either pulled ollama hosted image local image path jpeg, jpg, png backend either 'ellmer' 'ollamar', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" language language guide LLM model outputs ... pass generate args model args like temperature. set temperature 0 deterministic output","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_alt_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image Alt Text using LLMs — llm_image_alt_text","text":"df text","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_alt_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image Alt Text using LLMs — llm_image_alt_text","text":"","code":"if (FALSE) { # \\dontrun{ llm_image_alt_text(  llm_model = \"qwen2.5vl\",  image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),  backend = 'ellmer',  additional_prompt = \"\", provider = \"ollama\", language = \"English\" ) } # }"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_classification.html","id":null,"dir":"Reference","previous_headings":"","what":"Image Classification using LLMs — llm_image_classification","title":"Image Classification using LLMs — llm_image_classification","text":"Image Classification using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_classification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image Classification using LLMs — llm_image_classification","text":"","code":"llm_image_classification(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   language = \"English\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_classification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image Classification using LLMs — llm_image_classification","text":"llm_model local LLM model either pulled ollama hosted image local image path jpeg, jpg, png backend either 'ollamar' 'ellmer', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" language language guide LLM model outputs ... pass generate args model args like temperature","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_classification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image Classification using LLMs — llm_image_classification","text":"df image_classification, primary_object, secondary_object, image_description, image_colors, image_proba_names, image_proba_values","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_classification.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image Classification using LLMs — llm_image_classification","text":"","code":"if (FALSE) { # \\dontrun{ llm_image_classification(  llm_model = \"qwen2.5vl\",  image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),  backend = 'ellmer',  additional_prompt = \"\", provider = \"ollama\", language = \"English\" ) } # }"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_custom.html","id":null,"dir":"Reference","previous_headings":"","what":"Customized Vision using LLMs — llm_image_custom","title":"Customized Vision using LLMs — llm_image_custom","text":"Customized Vision using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_custom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Customized Vision using LLMs — llm_image_custom","text":"","code":"llm_image_custom(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   system_prompt = \"You are a terse assistant in computer vision sentiment.\",   image_prompt = \"return JSON describing image, do not include json or backticks\",   example_df = NULL,   provider = \"ollama\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_custom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Customized Vision using LLMs — llm_image_custom","text":"llm_model local LLM model either pulled ollama hosted image local image path jpeg, jpg, png backend either 'ollamar' 'ellmer' system_prompt overarching assistant description, please note LLM told return JSON kuzco handle conversions JSON image_prompt anything want really remind llm . example_df example data.frame show llm want returned note converted JSON LLM. provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" ... pass generate args model args like temperature","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_custom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Customized Vision using LLMs — llm_image_custom","text":"customized return based example_df custom control","code":""},{"path":[]},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_extract_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","title":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","text":"Image OCR Text Extraction using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_extract_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","text":"","code":"llm_image_extract_text(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/text_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   language = \"English\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_extract_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","text":"llm_model local LLM model either pulled ollama hosted image local image path jpeg, jpg, png backend either 'ellmer' 'ollamar', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" language language guide LLM model outputs ... pass generate args model args like temperature. set temperature 0 deterministic output","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_extract_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","text":"df text confidence score","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_extract_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","text":"","code":"if (FALSE) { # \\dontrun{ llm_image_extract_text(  llm_model = \"qwen2.5vl\",  image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),  backend = 'ellmer',  additional_prompt = \"\", provider = \"ollama\", language = \"English\" ) } # }"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_recognition.html","id":null,"dir":"Reference","previous_headings":"","what":"Image Recognition using LLMs — llm_image_recognition","title":"Image Recognition using LLMs — llm_image_recognition","text":"Image Recognition using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_recognition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image Recognition using LLMs — llm_image_recognition","text":"","code":"llm_image_recognition(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   recognize_object = \"face\",   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   language = \"English\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_recognition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image Recognition using LLMs — llm_image_recognition","text":"llm_model local LLM model either pulled ollama hosted image local image path jpeg, jpg, png recognize_object item want LLM look backend either 'ollamar' 'ellmer', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" language language guide LLM model outputs ... pass generate args model args like temperature. set temperature 0 deterministic output","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_recognition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image Recognition using LLMs — llm_image_recognition","text":"df object_recognized, object_count, object_description, object_location","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_recognition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image Recognition using LLMs — llm_image_recognition","text":"","code":"if (FALSE) { # \\dontrun{ llm_image_recognition(  llm_model = \"qwen2.5vl\",  image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   recognize_object = \"nose\",  backend = 'ellmer',  additional_prompt = \"\", provider = \"ollama\", language = \"English\" ) } # }"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Image Sentiment using LLMs — llm_image_sentiment","title":"Image Sentiment using LLMs — llm_image_sentiment","text":"Image Sentiment using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image Sentiment using LLMs — llm_image_sentiment","text":"","code":"llm_image_sentiment(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   language = \"English\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_sentiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image Sentiment using LLMs — llm_image_sentiment","text":"llm_model local LLM model either pulled ollama hosted image local image path jpeg, jpg, png backend either 'ollamar' 'ellmer', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" language language guide LLM model outputs ... pass generate args model args like temperature. set temperature 0 deterministic output","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_sentiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image Sentiment using LLMs — llm_image_sentiment","text":"df image_sentiment, image_score, sentiment_description, image_keywords","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_sentiment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image Sentiment using LLMs — llm_image_sentiment","text":"","code":"if (FALSE) { # \\dontrun{ llm_image_sentiment(  llm_model = \"qwen2.5vl\",  image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),  backend = 'ellmer',  additional_prompt = \"\", provider = \"ollama\", language = \"English\" ) } # }"},{"path":"https://frankiethull.github.io/kuzco/reference/view_image.html","id":null,"dir":"Reference","previous_headings":"","what":"View Images quickly and easily — view_image","title":"View Images quickly and easily — view_image","text":"View Images quickly easily","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View Images quickly and easily — view_image","text":"","code":"view_image(image = system.file(\"img/test_img.jpg\", package = \"kuzco\"))"},{"path":"https://frankiethull.github.io/kuzco/reference/view_image.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View Images quickly and easily — view_image","text":"image image view","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_image.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"View Images quickly and easily — view_image","text":"plot image Plots pane","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_image.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View Images quickly and easily — view_image","text":"","code":"view_image(image = system.file(\"img/test_img.jpg\", package = \"kuzco\"))"},{"path":"https://frankiethull.github.io/kuzco/reference/view_llm_results.html","id":null,"dir":"Reference","previous_headings":"","what":"view llm results as a tidy great table — view_llm_results","title":"view llm results as a tidy great table — view_llm_results","text":"view llm results tidy great table","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_llm_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"view llm results as a tidy great table — view_llm_results","text":"","code":"view_llm_results(llm_results)"},{"path":"https://frankiethull.github.io/kuzco/reference/view_llm_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"view llm results as a tidy great table — view_llm_results","text":"llm_results results one llm_image_* functions","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_llm_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"view llm results as a tidy great table — view_llm_results","text":"great table view results neatly","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_llm_results.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"view llm results as a tidy great table — view_llm_results","text":"","code":"if (FALSE) { # \\dontrun{ view_llm_results(llm_image_alt_text()) } # }"},{"path":"https://frankiethull.github.io/kuzco/news/index.html","id":"kuzco-010","dir":"Changelog","previous_headings":"","what":"kuzco 0.1.0","title":"kuzco 0.1.0","text":"CRAN release: 2026-01-26 initial CRAN release # kuzco 0.0.5.9000 remove references deprecated ellmer chat functions. add list_prompts edit_prompt reduce warnings & notes preparation CRAN submittal","code":""},{"path":"https://frankiethull.github.io/kuzco/news/index.html","id":"kuzco-0049000","dir":"Changelog","previous_headings":"","what":"kuzco 0.0.4.9000","title":"kuzco 0.0.4.9000","text":"add language argument ease--use. enables multilingual LLMs return different languages. add multilingual-support.qmd vignette showcase new option.","code":""},{"path":"https://frankiethull.github.io/kuzco/news/index.html","id":"kuzco-0039000","dir":"Changelog","previous_headings":"","what":"kuzco 0.0.3.9000","title":"kuzco 0.0.3.9000","text":"Gemini 2.5 Pro rewrites system prompts kuzco, improving structured return robustness. add site (https://frankiethull.github.io/kuzco/)","code":""},{"path":"https://frankiethull.github.io/kuzco/news/index.html","id":"kuzco-0029000","dir":"Changelog","previous_headings":"","what":"kuzco 0.0.2.9000","title":"kuzco 0.0.2.9000","text":"MAJOR CHANGE: add support cloud providers addition local models. pre-0.0.2.9000 kuzco supported Ollama. Now supports LLM providers via ellmer add cloud-providers.qmd vignette","code":""},{"path":"https://frankiethull.github.io/kuzco/news/index.html","id":"kuzco-00171","dir":"Changelog","previous_headings":"","what":"kuzco 0.0.1.71","title":"kuzco 0.0.1.71","text":"add new helpers /O application: view_image, view_llm_results, & kuzco_app","code":""}]
