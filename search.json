[{"path":"https://frankiethull.github.io/kuzco/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 kuzco authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://frankiethull.github.io/kuzco/articles/cloud-providers.html","id":"local-llms","dir":"Articles","previous_headings":"","what":"local LLMs","title":"cloud-providers","text":"kuzco originally designed work local LLMs “ollamar.” models run using Ollama, supports “ollamar” “ellmer” backends. installing Ollama system, need pull model use locally. install Ollama pull model (preferably vision model) qwen2.5vl install kuzco run AI enabled computer vision tasks Ollama served default provider time, check getting-started README local examples. kuzco can now also utilize cloud-based providers.","code":""},{"path":"https://frankiethull.github.io/kuzco/articles/cloud-providers.html","id":"cloud-llms","dir":"Articles","previous_headings":"","what":"cloud LLMs","title":"cloud-providers","text":"recent months, kuzco attracted significant interest organizations like R-Consortium Posit, well individuals curating lists LLM AI projects R open-source communities. Many users highlighted need supporting non-local LLMs, whether due hardware limitations desire leverage API account Mistral, Google, OpenAI, etc. Given feedback, adding non-local LLM functionality kuzco logical next step. Note provider = \"ollama\" default, change interfere legacy processes. However, “ellmer” backend selected (also default), option change provider needed. Note showcases use Mistral provider. Since cloud providers require API key, API key can set like : exact environment variable use via ellmer. ’re unsure name API key, refer documentation provider ellmer documentation chat provider. ’ve set environment variable, running computer vision tasks becomes straightforward: reference, complete list “providers” available kuzco, along corresponding ellmer “chat” functions:","code":"# via base R: Sys.setenv(MISTRAL_API_KEY = \"the_api_key_via_the_provider\") # or usethis: usethis::edit_r_environ() kuzco::llm_image_classification(provider = \"mistral\", llm_model = \"pixtral-12b\", image = test_img)"},{"path":"https://frankiethull.github.io/kuzco/articles/cloud-providers.html","id":"cloud-example","dir":"Articles","previous_headings":"","what":"cloud example","title":"cloud-providers","text":"Note provider = \"ollama\" default, change interfere legacy processes. However, “ellmer” backend selected (also default), option change provider needed. Note showcases use Mistral provider. Since cloud providers require API key, API key can set like : exact environment variable use via ellmer. ’re unsure name API key, refer documentation provider ellmer documentation chat provider. ’ve set environment variable, running computer vision tasks becomes straightforward:","code":"# via base R: Sys.setenv(MISTRAL_API_KEY = \"the_api_key_via_the_provider\") # or usethis: usethis::edit_r_environ() kuzco::llm_image_classification(provider = \"mistral\", llm_model = \"pixtral-12b\", image = test_img)"},{"path":"https://frankiethull.github.io/kuzco/articles/cloud-providers.html","id":"cloud-provider-dictionary","dir":"Articles","previous_headings":"","what":"cloud provider dictionary","title":"cloud-providers","text":"reference, complete list “providers” available kuzco, along corresponding ellmer “chat” functions:","code":""},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"a-typical-workflow-for-a-single-image","dir":"Articles","previous_headings":"","what":"a typical workflow for a single image","title":"getting-started","text":"image within kuzco get started. feel free substitute image image choice. make things easy, new function kuzco see image, view_image.  decide llm_image_* function call: - llm_image_alt_text - llm_image_classification - llm_image_extract_text - llm_image_recognition - llm_image_sentiment - llm_image_custom easily view results kuzco:","code":"my_image <- file.path(system.file(package = \"kuzco\", \"img/test_img.jpg\")) my_image |>   view_image() llm_results <-     my_image |>     llm_image_classification(llm_model = \"qwen2.5vl\") llm_results |>   view_llm_results() |>"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"define-a-path-to-an-image","dir":"Articles","previous_headings":"","what":"define a path to an image","title":"getting-started","text":"image within kuzco get started. feel free substitute image image choice.","code":"my_image <- file.path(system.file(package = \"kuzco\", \"img/test_img.jpg\"))"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"view-the-input-image","dir":"Articles","previous_headings":"","what":"view the input image","title":"getting-started","text":"make things easy, new function kuzco see image, view_image.","code":"my_image |>   view_image()"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"apply-computer-vision","dir":"Articles","previous_headings":"","what":"apply computer vision","title":"getting-started","text":"decide llm_image_* function call: - llm_image_alt_text - llm_image_classification - llm_image_extract_text - llm_image_recognition - llm_image_sentiment - llm_image_custom","code":"llm_results <-     my_image |>     llm_image_classification(llm_model = \"qwen2.5vl\")"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"view-the-output-results","dir":"Articles","previous_headings":"","what":"view the output results","title":"getting-started","text":"easily view results kuzco:","code":"llm_results |>   view_llm_results() |>"},{"path":"https://frankiethull.github.io/kuzco/articles/getting-started.html","id":"computer-vision-app","dir":"Articles","previous_headings":"","what":"computer vision app","title":"getting-started","text":"addtion, kuzco shiny app implementation within package. entire workflow can ran within GUI like :","code":"kuzco_app()"},{"path":"https://frankiethull.github.io/kuzco/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Frank Hull. Author, maintainer. Johannes Breuer. Contributor. Jordi Rosell. Contributor.","code":""},{"path":"https://frankiethull.github.io/kuzco/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hull F (2025). kuzco: LLM image classification using ollama R. R package version 0.0.2.9000, https://frankiethull.github.io/kuzco/.","code":"@Manual{,   title = {kuzco: LLM image classification using ollama in R},   author = {Frank Hull},   year = {2025},   note = {R package version 0.0.2.9000},   url = {https://frankiethull.github.io/kuzco/}, }"},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"kuzco-","dir":"","previous_headings":"","what":"LLM image classification using ollama in R","title":"LLM image classification using ollama in R","text":"{kuzco} simple vision boilerplate built ollama R, top {ollamar} & {ellmer}. {kuzco} designed computer vision assistant, giving local models guidance classifying images return structured data. goal standardize outputs image classification use LLMs alternative option keras torch. {kuzco} currently supports: classification, recognition, sentiment, text extraction, alt-text creation, custom computer vision tasks.","code":""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"LLM image classification using ollama in R","text":"can install development version kuzco like :","code":"devtools::install_github(\"frankiethull/kuzco\")"},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"LLM image classification using ollama in R","text":"basic example shows use kuzco. image want learn : picture puppy odin circa 2019.","code":"library(kuzco) library(ollamar) test_img <- file.path(system.file(package = \"kuzco\"), \"img/test_img.jpg\")"},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-for-image-classification","dir":"","previous_headings":"Example","what":"llm for image classification:","title":"LLM image classification using ollama in R","text":"","code":"llm_results <- llm_image_classification(llm_model = \"qwen2.5vl\", image = test_img,                                          backend = 'ollamar') llm_results |> tibble::as_tibble() #> # A tibble: 1 × 7 #>   image_classification primary_object secondary_object image_description         #>   <chr>                <chr>          <chr>            <chr>                     #> 1 puppy                puppy          face             a close-up of a puppy wi… #> # ℹ 3 more variables: image_colors <chr>, image_proba_names <list>, #> #   image_proba_values <list> llm_results |> str() #> 'data.frame':    1 obs. of  7 variables: #>  $ image_classification: chr \"puppy\" #>  $ primary_object      : chr \"puppy\" #>  $ secondary_object    : chr \"face\" #>  $ image_description   : chr \"a close-up of a puppy with a mix of black and white fur, looking directly at the camera with a curious expression.\" #>  $ image_colors        : chr \"#000000, #FFFFFF, #808080\" #>  $ image_proba_names   :List of 1 #>   ..$ : chr \"puppy, puppy face, fur, eyes, nose\" #>  $ image_proba_values  :List of 1 #>   ..$ : chr \"0.7, 0.2, 0.05, 0.05, 0.05\""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-for-image-sentiment","dir":"","previous_headings":"Example","what":"llm for image sentiment:","title":"LLM image classification using ollama in R","text":"","code":"llm_emotion <- llm_image_sentiment(llm_model = \"qwen2.5vl\", image = test_img)  llm_emotion |> str() #> 'data.frame':    1 obs. of  4 variables: #>  $ image_sentiment      : chr \"positive\" #>  $ image_score          : num 0.8 #>  $ sentiment_description: chr \"The image evokes feelings of warmth and affection due to the adorable appearance of the puppy.\" #>  $ image_keywords       : chr \"cute, lovable, friendly, cuddly, appealing\""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-for-image-recognition","dir":"","previous_headings":"Example","what":"llm for image recognition:","title":"LLM image classification using ollama in R","text":"note backend kuzco flexible well. allows users specify ‘ollamar’, suggests structured outputs, ‘ellmer’ enforces structured outputs.","code":"llm_detection <- llm_image_recognition(llm_model = \"qwen2.5vl\",                                         image = test_img,                                        recognize_object = \"nose\",                                        backend  = \"ollamar\")  llm_detection |> str() #> 'data.frame':    1 obs. of  4 variables: #>  $ object_recognized : chr \"yes\" #>  $ object_count      : int 1 #>  $ object_description: chr \"The nose is black and is located in the center of the image, slightly below the eyes.\" #>  $ object_location   : chr \"center\""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-for-image-text-extraction","dir":"","previous_headings":"Example","what":"llm for image text extraction:","title":"LLM image classification using ollama in R","text":"kuzco also useful OCR tasks, extracting text images showcased :","code":"text_img <- file.path(system.file(package = \"kuzco\"), \"img/text_img.jpg\")   text_img |> view_image() llm_extract_txt <- llm_image_extract_text(llm_model = \"qwen2.5vl\",                                            image = text_img,                                           backend  = \"ellmer\")  llm_extract_txt |> str() #> 'data.frame':    1 obs. of  2 variables: #>  $ text            : chr \"Picture of Odin as a puppy\" #>  $ confidence_score: num 0.95"},{"path":[]},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"llm-image-customization","dir":"","previous_headings":"newer features","what":"llm image customization:","title":"LLM image classification using ollama in R","text":"new feature kuzco, fully customizable function. allows users test computer vision techniques without leaving kuzco boilerplate.","code":"llm_customized <- llm_image_custom(llm_model = \"qwen2.5vl\",                                     image = test_img,                                    system_prompt = \"you are a dog breed expert, you know all about dogs.                                                      tell me the primary breed, secondary breed, and a brief description about both.\",                                    image_prompt  = \"tell me what kind of dog is in the image?\",                                    example_df = data.frame(                                      dog_breed_primary = \"hound\",                                      dog_breed_secondary = \"corgi\",                                      dog_breed_information = \"information about the primary and secondary breed\"                                    ))  llm_customized |> str() #> 'data.frame':    1 obs. of  3 variables: #>  $ dog_breed_primary    : chr \"Blue Heeler\" #>  $ dog_breed_secondary  : chr \"Cowboy Mix\" #>  $ dog_breed_information: chr \"Blue Heelers are a cattle-working breed known for their intelligence and herding abilities. The primary breed, \"| __truncated__"},{"path":[]},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"io-helpers","dir":"","previous_headings":"newer features > additional enhancements:","what":"i/o helpers","title":"LLM image classification using ollama in R","text":"kuzco now view_image & view_llm_results functions within package, making easy view images display llm results. addition , kuzco now features kuzco_app fully functioning shiny application within package. Making even easier computer vision LLMs R.","code":""},{"path":"https://frankiethull.github.io/kuzco/index.html","id":"cloud-based-llms","dir":"","previous_headings":"newer features > additional enhancements:","what":"cloud-based LLMs","title":"LLM image classification using ollama in R","text":"kuzco now supports LLM providers supported ellmer! ’s correct, can now send images Perplexity, Claude, OpenAI, Gemini, list goes . defaults “ollama” maintain original workflows. Cloud-hosted LLMs generally offer greater speed advanced capabilities, require users obtain API key since inference handled remotely. providers offer free tier usage limits, others . Keep mind using cloud-hosted LLM comes less privacy compared running model locally, enables access powerful, cutting-edge models. get started, users set API key environment select provider-hosted model supports image processing. mistral example using pixtral-12b, still pretty small model. leverages mistral’s compute, instead .","code":"# via base R: Sys.setenv(MISTRAL_API_KEY = \"the_api_key_via_the_provider\") # or usethis: usethis::edit_r_environ() kuzco::llm_image_classification(provider = \"mistral\", llm_model = \"pixtral-12b\", image = test_img) #>   image_classification primary_object secondary_object #> 1                  dog            dog              ear #>                                                              image_description #> 1 Close-up of a black and white dog with a red and black checkered background. #>                         image_colors               image_proba_names #> 1 #000000, #FFFFFF, #FF0000, #FF00FF dog, ear, fur, eyes, background #>          image_proba_values #> 1 0.6, 0.2, 0.1, 0.05, 0.05"},{"path":"https://frankiethull.github.io/kuzco/reference/chat_ellmer.html","id":null,"dir":"Reference","previous_headings":"","what":"chat ellmer — chat_ellmer","title":"chat ellmer — chat_ellmer","text":"minimal wrapper function switch provider used llm_image* function ellmer backend selected, ollamar supports ollama","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/chat_ellmer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"chat ellmer — chat_ellmer","text":"","code":"chat_ellmer(provider = \"ollama\")"},{"path":"https://frankiethull.github.io/kuzco/reference/chat_ellmer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"chat ellmer — chat_ellmer","text":"provider provider, \"ollama\", \"claude\", \"github\"","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco-package.html","id":null,"dir":"Reference","previous_headings":"","what":"kuzco: LLM image classification using ollama in R — kuzco-package","title":"kuzco: LLM image classification using ollama in R — kuzco-package","text":"package designed use local models image classification. prompts functions designed take input image supply classification information output.","code":""},{"path":[]},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"kuzco: LLM image classification using ollama in R — kuzco-package","text":"Maintainer: Frank Hull frankiethull@gmail.com contributors: Johannes Breuer johannes.breuer@gesis.org (ORCID) [contributor] Jordi Rosell jroselln@gmail.com (ORCID) [contributor]","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco_app.html","id":null,"dir":"Reference","previous_headings":"","what":"shiny kuzco app — kuzco_app","title":"shiny kuzco app — kuzco_app","text":"simple wrapper kuzco make computer vision everyone. -shot via frank hull shiny assistant (https://gallery.shinyapps.io/assistant/)","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/kuzco_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"shiny kuzco app — kuzco_app","text":"","code":"kuzco_app()"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_alt_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Image Alt Text using LLMs — llm_image_alt_text","title":"Image Alt Text using LLMs — llm_image_alt_text","text":"Image Alt Text using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_alt_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image Alt Text using LLMs — llm_image_alt_text","text":"","code":"llm_image_alt_text(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_alt_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image Alt Text using LLMs — llm_image_alt_text","text":"llm_model local LLM model pulled ollama image local image path jpeg, jpg, png backend either 'ellmer' 'ollamar', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" ... pass generate args model args like temperature. set temperature 0 deterministic output","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_alt_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image Alt Text using LLMs — llm_image_alt_text","text":"df text","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_classification.html","id":null,"dir":"Reference","previous_headings":"","what":"Image Classification using LLMs — llm_image_classification","title":"Image Classification using LLMs — llm_image_classification","text":"Image Classification using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_classification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image Classification using LLMs — llm_image_classification","text":"","code":"llm_image_classification(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_classification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image Classification using LLMs — llm_image_classification","text":"llm_model local LLM model pulled ollama image local image path jpeg, jpg, png backend either 'ollamar' 'ellmer', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" ... pass generate args model args like temperature","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_classification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image Classification using LLMs — llm_image_classification","text":"df image_classification, primary_object, secondary_object, image_description, image_colors, image_proba_names, image_proba_values","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_custom.html","id":null,"dir":"Reference","previous_headings":"","what":"Customized Vision using LLMs — llm_image_custom","title":"Customized Vision using LLMs — llm_image_custom","text":"Customized Vision using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_custom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Customized Vision using LLMs — llm_image_custom","text":"","code":"llm_image_custom(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   system_prompt =     \"You are a terse assistant specializing in computer vision image sentiment.\\n                   You are short and to the point. You only respond if the user supplies an image.\\n                   You will observe the image and return JSON specific answers.\\n                   Return as JSON\\n                   Do not include backticks or 'json' within your answer but purely the json.\\n                   Do not return NULL, all fields must be complete.\\n                   Do not return the exact examples given but fill out the template,\\n                   supply your own new original answer every time. \",   image_prompt = \"please return JSON for image according to the example format supplied\",   example_df = data.frame(image_sentiment = \"positive\", image_score = 0.6,     sentiment_description = \"image envokes a positive emotional response.\"),   provider = \"ollama\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_custom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Customized Vision using LLMs — llm_image_custom","text":"llm_model local LLM model pulled ollama image local image path jpeg, jpg, png backend either 'ollamar' 'ellmer' system_prompt overarching assistant description, please note LLM told return JSON kuzco handle conversions JSON image_prompt anything want really remind llm . example_df example data.frame show llm want returned note converted JSON LLM. provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" ... pass generate args model args like temperature","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_custom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Customized Vision using LLMs — llm_image_custom","text":"customized return based example_df custom control","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_extract_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","title":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","text":"Image OCR Text Extraction using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_extract_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","text":"","code":"llm_image_extract_text(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/text_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_extract_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","text":"llm_model local LLM model pulled ollama image local image path jpeg, jpg, png backend either 'ellmer' 'ollamar', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" ... pass generate args model args like temperature. set temperature 0 deterministic output","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_extract_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image OCR for Text Extraction using LLMs — llm_image_extract_text","text":"df text confidence score","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_recognition.html","id":null,"dir":"Reference","previous_headings":"","what":"Image Recognition using LLMs — llm_image_recognition","title":"Image Recognition using LLMs — llm_image_recognition","text":"Image Recognition using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_recognition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image Recognition using LLMs — llm_image_recognition","text":"","code":"llm_image_recognition(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   recognize_object = \"face\",   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_recognition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image Recognition using LLMs — llm_image_recognition","text":"llm_model local LLM model pulled ollama image local image path jpeg, jpg, png recognize_object item want LLM look backend either 'ollamar' 'ellmer', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" ... pass generate args model args like temperature. set temperature 0 deterministic output","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_recognition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image Recognition using LLMs — llm_image_recognition","text":"df object_recognized, object_count, object_description, object_location","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Image Sentiment using LLMs — llm_image_sentiment","title":"Image Sentiment using LLMs — llm_image_sentiment","text":"Image Sentiment using LLMs","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image Sentiment using LLMs — llm_image_sentiment","text":"","code":"llm_image_sentiment(   llm_model = \"qwen2.5vl\",   image = system.file(\"img/test_img.jpg\", package = \"kuzco\"),   backend = \"ellmer\",   additional_prompt = \"\",   provider = \"ollama\",   ... )"},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_sentiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image Sentiment using LLMs — llm_image_sentiment","text":"llm_model local LLM model pulled ollama image local image path jpeg, jpg, png backend either 'ollamar' 'ellmer', note 'ollamar' suggests structured outputs 'ellmer' enforces structured outputs additional_prompt text append image prompt provider backend = 'ollamar', provider ignored. backend = 'ellmer', provider refers ellmer::chat_* providers can used switch \"ollama\" providers \"perplexity\" ... pass generate args model args like temperature. set temperature 0 deterministic output","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/llm_image_sentiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image Sentiment using LLMs — llm_image_sentiment","text":"df image_sentiment, image_score, sentiment_description, image_keywords","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_image.html","id":null,"dir":"Reference","previous_headings":"","what":"View Images quickly and easily — view_image","title":"View Images quickly and easily — view_image","text":"View Images quickly easily","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View Images quickly and easily — view_image","text":"","code":"view_image(image = system.file(\"img/test_img.jpg\", package = \"kuzco\"))"},{"path":"https://frankiethull.github.io/kuzco/reference/view_image.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View Images quickly and easily — view_image","text":"image image view","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_image.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"View Images quickly and easily — view_image","text":"plot image Plots pane","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_llm_results.html","id":null,"dir":"Reference","previous_headings":"","what":"view llm results as a tidy great table — view_llm_results","title":"view llm results as a tidy great table — view_llm_results","text":"view llm results tidy great table","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_llm_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"view llm results as a tidy great table — view_llm_results","text":"","code":"view_llm_results(llm_results)"},{"path":"https://frankiethull.github.io/kuzco/reference/view_llm_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"view llm results as a tidy great table — view_llm_results","text":"llm_results results one llm_image_* functions","code":""},{"path":"https://frankiethull.github.io/kuzco/reference/view_llm_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"view llm results as a tidy great table — view_llm_results","text":"great table view results neatly","code":""}]
